{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b97942-e5cd-486a-a07c-d00eadd2b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3cf5e0-7b54-43d6-83f8-072eb2b03600",
   "metadata": {},
   "source": [
    "# 例子-分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e96b70-3c40-426e-84dc-7f71c50a5fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8957212567329407}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 仅指定任务时，使用默认模型（不推荐）\n",
    "pipe = pipeline(\"sentiment-analysis\")\n",
    "pipe(\"今儿上海可真冷啊\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2f9a9f-6efb-410f-94ff-5d0a3e6391cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9238728880882263}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"我觉得这家店蒜泥白肉的味道一般\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03dbc9e-2fd4-4454-abcb-752865a6e0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8578681349754333}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认使用的模型 distilbert-base-uncased-finetuned-sst-2-english \n",
    "# 并未针对中文做太多训练，中文的文本分类任务表现未必满意\n",
    "pipe(\"你学东西真的好快，理论课一讲就明白了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449c43a1-f5a3-4014-9775-b10695b9c5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9961802959442139}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 替换为英文后，文本分类任务的表现立刻改善\n",
    "pipe(\"You learn things really quickly. You understand the theory class as soon as it is taught.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3221aee9-3e9a-465e-adcf-94893c36f9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995032548904419}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Today Shanghai is really cold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1a8c46-bc02-475c-8c86-10df65a7dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995032548904419},\n",
       " {'label': 'NEGATIVE', 'score': 0.9984821677207947},\n",
       " {'label': 'POSITIVE', 'score': 0.9961802959442139}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"Today Shanghai is really cold.\",\n",
    "    \"I think the taste of the garlic mashed pork in this store is average.\",\n",
    "    \"You learn things really quickly. You understand the theory class as soon as it is taught.\"\n",
    "]\n",
    "\n",
    "pipe(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af9bf5-ee7a-4515-8a4a-5b08206be6bf",
   "metadata": {},
   "source": [
    "# 例子-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00e8344-c969-4e5b-ba93-0f10a0d14a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d22fc5a3fc48aba003db3335ec1325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a5f0a266eb4803b933ebfe7257e003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555e5657190240aa9a3683a06ba12bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9542fd3464d85a6f63eb9a8eced77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde551d4-76cd-4d17-bbf8-d879ada1008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b38b894-2268-4031-b7e4-2d42dbfe1ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/root/miniconda3/envs/transformers/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9674639,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 0,\n",
       "  'end': 12},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99828726,\n",
       "  'word': 'French',\n",
       "  'start': 18,\n",
       "  'end': 24},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99896103,\n",
       "  'word': 'New York City',\n",
       "  'start': 42,\n",
       "  'end': 55}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\", grouped_entities=True)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba1f39-8cd1-4653-b164-051a02d6ab97",
   "metadata": {},
   "source": [
    "# 例子-智能问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7885ef92-8a23-41f0-919d-389d2701f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3672c46ec24ccf90720f0247e1f660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b57955c1de3496bab32f4602ce2fc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c96e6c3830458ea2179648170c98e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe106dfbd3a64d96b1a50dcfdb9f6be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba7b02f447f4254803d6919cdf0e7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(task=\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49c2a00-9008-4a10-a580-7dff56903ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9327, start: 30, end: 54, answer: huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd5fdf8-cc2f-496c-8e03-ba1ff349152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9458, start: 115, end: 122, answer: Beijing\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the capital of China?\",\n",
    "    context=\"On 1 October 1949, CCP Chairman Mao Zedong formally proclaimed the People's Republic of China in Tiananmen Square, Beijing.\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd42deb-f409-4883-b441-b22a852daa60",
   "metadata": {},
   "source": [
    "# 例子-摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85fd88c-6937-45f5-91c6-919e4df9bd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7fa9d4ab49494eafa6a636fece19c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e978284f71a48769799df073f1ef828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46d4670146848de9cbf5f90151951fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17972583d1b94f06b831737d9de5938b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9de7790a24341079aae27ec4861c5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/transformers/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"t5-base\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827c8d74-4971-4d47-adfe-92ce9e628ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decode'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078873c7-8e6f-4317-93cd-505468b7fddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'large language models (LLMs) are very large deep learning models pre-trained on vast amounts of data . transformers are capable of un'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    '''\n",
    "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data. \n",
    "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. \n",
    "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
    "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning. \n",
    "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
    "    Unlike earlier recurrent neural networks (RNN) that sequentially process inputs, transformers process entire sequences in parallel. \n",
    "    This allows the data scientists to use GPUs for training transformer-based LLMs, significantly reducing the training time.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea55f9-85da-4b69-aefa-2449eb758469",
   "metadata": {},
   "source": [
    "# 例子-语音分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef4ce04-69f7-4fcd-9c0f-f16d55f92a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b87ccc38d6447478aaa30019c6f714c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9311fc431e2b4716b5f0cfebb9724b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at superb/hubert-base-superb-er were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at superb/hubert-base-superb-er and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f3238d8601452b9b42d57af0ddb520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/213 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e57544e-6ab0-44ba-9c8e-6575d23f3bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4532, 'label': 'hap'},\n",
       " {'score': 0.3622, 'label': 'sad'},\n",
       " {'score': 0.0943, 'label': 'neu'},\n",
       " {'score': 0.0903, 'label': 'ang'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 Hugging Face Datasets 上的测试文件\n",
    "preds = classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de03f969-f3ee-461e-9653-c832465b59f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4532, 'label': 'hap'},\n",
       " {'score': 0.3622, 'label': 'sad'},\n",
       " {'score': 0.0943, 'label': 'neu'},\n",
       " {'score': 0.0903, 'label': 'ang'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用本地的音频文件做测试\n",
    "preds = classifier(\"data/audio/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ef814-3c4d-4fc9-8de8-a722180e4aa4",
   "metadata": {},
   "source": [
    "# 例子-语音识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49901acf-4bed-421a-94a2-f03ae9c04690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6de1524154e46478ab967d6cd28ac8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664f904673c046a28c0114420986476c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284979d149dd42c5bbca9f275c7b6d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a43d4ca9b914d749b2313e4b2c17b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9728c173940f4473af3cd2a504b89b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1922e755a2d416f8e3a211aac7724ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96f68232dc342bca0d9987dbc082318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72baf588eef64983a4b49827352b9636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9179df3933364d5281c69c8348714f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911e8be6f5994475b26ca104a975325a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1afcdf89c84b649b55b737e086514d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "114767dd-88a8-47c2-9d4b-c4e8b1c35865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = transcriber(\"data/audio/mlk.flac\")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063df20-4bfd-47bc-b67a-fb5d436f735a",
   "metadata": {},
   "source": [
    "# 例子-图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7bb3a3f-fda0-42e2-af0f-1f896e6a6feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76bf809b3fa44ef8eec26c0941bd95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4701ef079765404594529a384d9254ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1a5974ad40488a8f4089ae506683e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0336851-28fe-475c-9dcc-b8eed824b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "{'score': 0.0229, 'label': 'tiger cat'}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c609a0d1-d4c4-406b-95d4-728c7cb9d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "{'score': 0.0229, 'label': 'tiger cat'}\n"
     ]
    }
   ],
   "source": [
    "# 使用本地图片（狼猫）\n",
    "preds = classifier(\n",
    "    \"data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880c0d3-c613-4451-9349-caddb811c973",
   "metadata": {},
   "source": [
    "# 例子-物体检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9d45220-e15c-4569-8d91-b57cc9c10da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 2729413 (https://huggingface.co/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f93f778f314b2f91f0cd3a09770030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db52dd21d194096af149bc34988d484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a85fea7f1244f591cbfc25c3b618b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adde6ab002d4403c97694a436583bb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/274 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "detector = pipeline(task=\"object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb80d25a-609e-430c-8408-1dab7545c8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9864,\n",
       "  'label': 'cat',\n",
       "  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0452a13-8da9-473c-9521-40a8b53c5eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9864,\n",
       "  'label': 'cat',\n",
       "  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7193b-c746-4897-b754-1d1af6234220",
   "metadata": {},
   "source": [
    "# 例子-使用GPT-2实现文本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "258c6d0e-fc52-45eb-82a2-67b1a81a3f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399fe2998afc43249b58d01809d4bbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162b533e7c0043f5bd0fc986a8a2c31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ea8e5e13e49ebb8a48954fffb9d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c523c9759cf4bb38cd79b3a91075362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c892964f39a43b6ba4b8f944b94889b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dcaf3381094c20af25968acc8d4c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hugging Face is a community-based open-source platform for machine learning. Users can connect freely with the world of machine learning without even taking a web connection. We provide an alternative to traditional AI in this world of computer AI, and support the'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "prompt = \"Hugging Face is a community-based open-source platform for machine learning.\"\n",
    "generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
    "generator(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bc748de-60b6-4fd3-8f6e-abfc436ad6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"You are very smart\"\n",
    "generator = pipeline(task=\"text-generation\", model=\"gpt2\", num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcd7b070-2337-449e-8e60-ba172fe1cc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'You are very smart and you will teach me the secrets and the techniques of every kind of magician.\"\\n\\n\"Of course I will because I like to watch movies with you. I will teach you, I will learn everything you can on your personal'},\n",
       " {'generated_text': 'You are very smart to be right here, sir,\" she whispered softly to him as she pulled away the phone. Her voice was faint as her eyes remained focused on his ear. \"I don\\'t think I know where things are. So take your'},\n",
       " {'generated_text': \"You are very smart and very bright. So that was the plan and then you came at the next one. We're going to find that out. And I love that.\\n\\nSo that was the plan after that.\\n\\nThat's good\"}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d6dd77b-d358-46e2-84e1-0772224eac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'You are very smart. You have good manners. You are honest and honest as fuck. You are a very nice person. That\\'s why you always talk about people being lazy.\"\\n\\nThe real-life details of those admissions go back to the'},\n",
       " {'generated_text': 'You are very smart. You have many different things going on and you will be the best manager in the world.\"\\n\\nThere is no question that he is in great shape. The former World Cup winner has missed four of his 18 matches with a'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(prompt, num_return_sequences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4cc155b-2a94-4248-a144-171b9076fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'You are very smart.\\n\\nIn this video, you are about to become'},\n",
       " {'generated_text': 'You are very smart, and you want to do something meaningful for people and to'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(prompt, num_return_sequences=2, max_length=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c11d09-215b-4732-91c5-1133cc439004",
   "metadata": {},
   "source": [
    "# 例子-使用BERT-Base-Chinese实现中文补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "477da019-b78d-4d86-ab80-6037cb63a06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad2fabe647840538ab33a6ef68b695d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d321e02e1c455dbc38daf148c3c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc7dfd264504deab2ab5677111afe79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd6215cf25d4c269071a267f4bf800c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3746381daba5413ebcd8755a01f8297a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(task=\"fill-mask\", model=\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9fcc6a1-127b-4c31-be5b-cb3b6fb4b782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9203723669052124,\n",
       "  'token': 679,\n",
       "  'token_str': '不',\n",
       "  'sequence': '人 民 是 不 可 战 胜 的'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"人民是[MASK]可战胜的\"\n",
    "\n",
    "fill_mask(text, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "033e288e-8fed-4fa2-8246-503c62cb22e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7596911191940308,\n",
       "  'token': 8043,\n",
       "  'token_str': '？',\n",
       "  'sequence': '美 国 的 首 都 是 ？'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"美国的首都是[MASK]\"\n",
    "\n",
    "fill_mask(text, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e0474a4-24fa-4dcb-b5e6-d524099e0d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9911912083625793,\n",
       "  'token': 3791,\n",
       "  'token_str': '法',\n",
       "  'sequence': '巴 黎 是 法 国 的 首 都 。'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"巴黎是[MASK]国的首都。\"\n",
    "fill_mask(text, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2064215-b1a8-44e0-a33f-2eab1bc49f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7596911191940308,\n",
       "  'token': 8043,\n",
       "  'token_str': '？',\n",
       "  'sequence': '美 国 的 首 都 是 ？'},\n",
       " {'score': 0.21126744151115417,\n",
       "  'token': 511,\n",
       "  'token_str': '。',\n",
       "  'sequence': '美 国 的 首 都 是 。'},\n",
       " {'score': 0.026834219694137573,\n",
       "  'token': 8013,\n",
       "  'token_str': '！',\n",
       "  'sequence': '美 国 的 首 都 是 ！'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"美国的首都是[MASK]\"\n",
    "fill_mask(text, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5176d74c-8e53-40bc-a925-79ea0730b927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.5740261673927307,\n",
       "   'token': 5294,\n",
       "   'token_str': '纽',\n",
       "   'sequence': '[CLS] 美 国 的 首 都 是 纽 [MASK] [MASK] [SEP]'}],\n",
       " [{'score': 0.4926738142967224,\n",
       "   'token': 5276,\n",
       "   'token_str': '约',\n",
       "   'sequence': '[CLS] 美 国 的 首 都 是 [MASK] 约 [MASK] [SEP]'}],\n",
       " [{'score': 0.9353252053260803,\n",
       "   'token': 511,\n",
       "   'token_str': '。',\n",
       "   'sequence': '[CLS] 美 国 的 首 都 是 [MASK] [MASK] 。 [SEP]'}]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"美国的首都是[MASK][MASK][MASK]\"\n",
    "\n",
    "fill_mask(text, top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b6d66-48d7-49ff-99cc-df543e53e904",
   "metadata": {},
   "source": [
    "# 例子-使用 BERT Tokenizer 编码文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32f887d7-e7e4-4c15-a647-6303a2a41f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"bert-base-chinese\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aaa0f7c2-f889-4298-83ef-2d23e3b5749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['美', '国', '的', '首', '都', '是', '华', '盛', '顿', '特', '区']\n"
     ]
    }
   ],
   "source": [
    "# 第一步：分词\n",
    "sequence = \"美国的首都是华盛顿特区\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8697d33e-03c5-4732-b583-f98d9634be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二步：映射\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23475be7-f79a-4dde-bddc-fd180019156c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5401, 1744, 4638, 7674, 6963, 3221, 1290, 4670, 7561, 4294, 1277]\n"
     ]
    }
   ],
   "source": [
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c8c2740-91cd-402b-a748-bb0925389883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 5401, 1744, 4638, 7674, 6963, 3221, 1290, 4670, 7561, 4294, 1277, 102]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_e2e = tokenizer.encode(sequence)\n",
    "token_ids_e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79e2305a-1206-45e0-90c4-383f17e15ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'美 国 的 首 都 是 华 盛 顿 特 区'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a89ea61-0cf5-42b7-a50f-5efa86254223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 美 国 的 首 都 是 华 盛 顿 特 区 [SEP]'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_ids_e2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1809c8ab-7c53-4ca2-9458-8f4e45c1c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码多段文本\n",
    "sequence_batch = [\"美国的首都是华盛顿特区\", \"中国的首都是北京\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aaefa6c1-1ac9-457b-a90f-b8c03889fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_batch = tokenizer.encode(sequence_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ffe343a-0b32-4229-a2f4-5692207eed56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 美 国 的 首 都 是 华 盛 顿 特 区 [SEP] 中 国 的 首 都 是 北 京 [SEP]'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_ids_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c771f92-cf8b-4e5f-a5f1-4eb71a0f837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 5401, 1744, 4638, 7674, 6963, 3221, 1290, 4670, 7561, 4294, 1277, 102, 704, 1744, 4638, 7674, 6963, 3221, 1266, 776, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 综合\n",
    "embedding_batch = tokenizer(\"美国的首都是华盛顿特区\", \"中国的首都是北京\")\n",
    "print(embedding_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97c62179-864b-4c06-83ff-6a0888946049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [101, 5401, 1744, 4638, 7674, 6963, 3221, 1290, 4670, 7561, 4294, 1277, 102, 704, 1744, 4638, 7674, 6963, 3221, 1266, 776, 102]\n",
      "\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 优化下输出结构\n",
    "for key, value in embedding_batch.items():\n",
    "    print(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f64651ab-d3f2-4223-84b4-13248dec55b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [101, 5401, 1744, 4638, 7674, 6963, 3221, 1290, 4670, 7561, 4294, 1277, 102, 704, 1744, 4638, 7674, 6963, 3221, 1266, 776, 102]\n",
      "\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 优化下输出结构\n",
    "for key, value in embedding_batch.items():\n",
    "    print(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bb12376-06ff-4e04-9962-7b2512342f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加常规Token\n",
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74297023-b7ea-40e2-9945-0c925019be1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango: 12645\n",
      "##削: 14238\n",
      "##lmer: 12763\n",
      "##穴: 18011\n",
      "愉: 2690\n",
      "loft: 12751\n",
      "痙: 4577\n",
      "##癥: 17682\n",
      "##迹: 19896\n",
      "効: 1230\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# 使用 islice 查看词表部分内容\n",
    "for key, value in islice(tokenizer.vocab.items(), 10):\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76da0909-766e-4231-a5cb-9fbcec676ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = [\"天干\", \"地支\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc252931-ddc8-4dc0-9394-512171f078fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将集合作差结果添加到词表中\n",
    "new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6be4088c-c9d5-4802-90d3-13d4feaf6a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'地支', '天干'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31916b5d-2e8e-4577-ac55-7dd2ab681466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f0eb4b1-e315-4826-a17a-5e031d622356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21130"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新增加了2个Token，词表总数由 21128 增加到 21130\n",
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ea0dfcc-3d5f-460e-9d66-91d48d1e4bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21130"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新增加了2个Token，词表总数由 21128 增加到 21130\n",
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fab96568-4e80-499b-b00f-ab4ae0799693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加特殊Token（审慎操作）\n",
    "new_special_token = {\"sep_token\": \"NEW_SPECIAL_TOKEN\"}\n",
    "\n",
    "tokenizer.add_special_tokens(new_special_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8d1fde3-466f-4e4f-b78f-f88034534828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21131"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新增加了1个特殊Token，词表总数由 21128 增加到 21131\n",
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be835c-7775-4e3f-a9e1-0472583e677a",
   "metadata": {},
   "source": [
    "# 例子-保存Model和Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d282ca56-ff5c-4243-87b1-bfafbae4b95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/new-bert-base-chinese/tokenizer_config.json',\n",
       " './models/new-bert-base-chinese/special_tokens_map.json',\n",
       " './models/new-bert-base-chinese/vocab.txt',\n",
       " './models/new-bert-base-chinese/added_tokens.json',\n",
       " './models/new-bert-base-chinese/tokenizer.json')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./models/new-bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "177633cd-779a-4905-9329-bfd7d5d72450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./models/new-bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406ed2f-32b5-48ee-846c-bc61431360e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HCZ",
   "language": "python",
   "name": "hcz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
