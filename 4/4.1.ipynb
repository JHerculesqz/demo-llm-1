{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e588e55-8888-48ca-af85-e63e9a893b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置Jupyter Notebook代理\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "\n",
    "\n",
    "os.environ['HF_HOME'] = '/root/autodl-tmp/cache/huggingface/hub/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47348cd9-77fe-4e10-8b0c-d242d1b222b3",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfec3b-aa80-40a0-a8bd-7f48d89c34e8",
   "metadata": {},
   "source": [
    "## 使用Datasets下载开源数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8878c54-b579-4cd5-9709-fc8de221b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\", cache_dir=\"/root/autodl-tmp/cache/huggingface/hub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecad042d-26e8-4688-9277-0a7d24cf7ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25aa110c-55f4-46ac-b9ca-0d0275aa3948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"As far as Starbucks go, this is a pretty nice one.  The baristas are friendly and while I was here, a lot of regulars must have come in, because they bantered away with almost everyone.  The bathroom was clean and well maintained and the trash wasn't overflowing in the canisters around the store.  The pastries looked fresh, but I didn't partake.  The noise level was also at a nice working level - not too loud, music just barely audible.\\\\n\\\\nI do wish there was more seating.  It is nice that this location has a counter at the end of the bar for sole workers, but it doesn't replace more tables.  I'm sure this isn't as much of a problem in the summer when there's the space outside.\\\\n\\\\nThere was a treat receipt promo going on, but the barista didn't tell me about it, which I found odd.  Usually when they have promos like that going on, they ask everyone if they want their receipt to come back later in the day to claim whatever the offer is.  Today it was one of their new pastries for $1, I know in the summer they do $2 grande iced drinks with that morning's receipt.\\\\n\\\\nOverall, nice working or socializing environment.  Very friendly and inviting.  It's what I've come to expect from Starbucks, so points for consistency.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ef457a-b410-4263-bb4b-aefb2f6f4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ece84e-681c-45f2-8858-5cc50f88c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6071e2d3-89df-495d-8261-0ec6b4f77604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Service was horrific. Don't expect courteous bar tenders. They must not be working for tips because they couldn't give an ef less about any thing other than playing their own video poker or having a smoke break. You're more of an inconvenience to them than a customer. I'm referring specifically to the older woman and her daughter. Once again, horrific service! Blatantly bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 star</td>\n",
       "      <td>You get what you pay for is the best way to describe this place.  We made the mistake of waiting until Memorial Day Weekend to get our mani/pedis and EVERYTHING was booked.  We tried to push them to their creative limits which were just not what we were looking for unfortunately.  The women working were plenty nice I just prefer a little more.....quirk.  \\n\\nIt's been a week and my nails are chipping and have the little \\\"crackle\\\" on the tips.  I do the gel mani's so they typically last me for anywhere from 3-4 weeks!  I'm disappointed, but not surprised.  I will forever travel to Pink Polish in Chandler for my favorite girls to do my mani/pedis! :)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf8b1dd-b4bc-4512-ad47-b40d151e45a7",
   "metadata": {},
   "source": [
    "## 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347d9035-dd5e-4158-858d-ec9bb84569b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da98d58a-9e61-4621-bac1-270cda3995c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa3bc01-76d5-480d-b49f-3ef4f6f56cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Horrible!! Brought my iPad 2 in with a broken screen. I called ahead of time and was told it would be $100 but when I came in I was told it would be $130. I should have walked out the door then but I didn't. I came the next day to pick it up and it had a dent in the corner where they pryed the screen off. When I went to take the screen protector off the entire glass lifted from the device. So, I left it there and came back two days later. They tried to fix the dent but the iPad no longer fits in my case. The menu button was turned sideways and there are gaps all around the edges between the glass and device. And worst of all, they expected me to pay full price. I asked for a discount and was given 10%. Unbelievable, I hate making a scene so I just paid it. But I will be posting this review anywhere I can.    For the same price you can get MUCH better service elsewhere. STAY AWAY!!!!</td>\n",
       "      <td>[101, 9800, 27788, 106, 106, 139, 14929, 1204, 1139, 178, 24300, 123, 1107, 1114, 170, 3088, 3251, 119, 146, 1270, 3075, 1104, 1159, 1105, 1108, 1500, 1122, 1156, 1129, 109, 1620, 1133, 1165, 146, 1338, 1107, 146, 1108, 1500, 1122, 1156, 1129, 109, 7029, 119, 146, 1431, 1138, 2045, 1149, 1103, 1442, 1173, 1133, 146, 1238, 112, 189, 119, 146, 1338, 1103, 1397, 1285, 1106, 3368, 1122, 1146, 1105, 1122, 1125, 170, 10552, 1204, 1107, 1103, 2655, 1187, 1152, 185, 1616, 1174, 1103, 3251, 1228, 119, 1332, 146, 1355, 1106, 1321, 1103, 3251, 23476, 1228, 1103, 2072, 2525, 3358, 1121, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d718137-efa9-4275-bd83-b7634ccc25f1",
   "metadata": {},
   "source": [
    "## 数据抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0e2415-8f55-4211-b753-961f7f71a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "total_train_dataset = tokenized_datasets[\"train\"]\n",
    "total_eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7038ad-f929-44ce-b241-04e39bc83069",
   "metadata": {},
   "source": [
    "# 微调训练配置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea12258-2fa1-45dd-8cea-25ec93f29ac9",
   "metadata": {},
   "source": [
    "## 加载 BERT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37b74d3f-572f-49ed-b30e-33e1d8040a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e2f77-af9b-4a66-a558-61973b06631d",
   "metadata": {},
   "source": [
    "## 训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc7e7c1-1bad-4876-9d8d-092003e427ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "model_dir = \"/root/autodl-tmp/models/bert-base-cased-finetune-yelp\"\n",
    "\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e45c0d5-e1a8-4da6-8e16-515cc4f02293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/root/autodl-tmp/models/bert-base-cased-finetune-yelp/runs/Feb17_06-12-16_autodl-container-cac311993c-addb85b2,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "output_dir=/root/autodl-tmp/models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/root/autodl-tmp/models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 完整的超参数配置\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ec175-88b8-4e5b-9e0e-d654e18a3408",
   "metadata": {},
   "source": [
    "## 训练过程中的指标评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7102964c-992d-4a0a-8260-69a461f5d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fae0a1c9-f6f5-4cd8-8d4c-ff343c82b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267d5a3-c9e1-45a9-9e40-7021395f48c3",
   "metadata": {},
   "source": [
    "## 训练过程指标监控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df64ad87-8216-4748-8228-c20ba821cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695461a-a1f4-4635-b94c-dcccc5d77006",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71e1b075-1023-477f-82b6-dff67d3783f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=total_train_dataset, # small_train_dataset\n",
    "    eval_dataset=total_eval_dataset, # small_eval_dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a9c9500-cc70-4cad-bc44-112877099592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121875' max='121875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121875/121875 4:46:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.761560</td>\n",
       "      <td>0.682700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>0.731767</td>\n",
       "      <td>0.692080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=121875, training_loss=0.20778199127979768, metrics={'train_runtime': 17201.3966, 'train_samples_per_second': 113.363, 'train_steps_per_second': 7.085, 'total_flos': 5.130803778048e+17, 'train_loss': 0.20778199127979768, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train(resume_from_checkpoint=False)\n",
    "trainer.train(resume_from_checkpoint=True) # 加上断点续训啊，朋友"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "119b3545-f4c4-42c5-95b5-d7832254b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100))\n",
    "total_test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de69c178-7cc0-467e-b570-5a59620d1d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 07:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7317665815353394,\n",
       " 'eval_accuracy': 0.69208,\n",
       " 'eval_runtime': 467.1644,\n",
       " 'eval_samples_per_second': 107.029,\n",
       " 'eval_steps_per_second': 13.379,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(total_test_dataset) # small_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4bea2-ad57-4eee-92b6-02d5fd1733ac",
   "metadata": {},
   "source": [
    "## 保存模型和训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bccf509c-d09a-4320-9597-dfcd2792bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6909754b-6e26-4e28-bb49-c5fc1d3e2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f82445-ae80-424f-8925-14751f91ba58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HCZ",
   "language": "python",
   "name": "hcz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
